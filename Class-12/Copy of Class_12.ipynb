{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":108520,"status":"ok","timestamp":1721827560130,"user":{"displayName":"Abu Taher","userId":"13405938316250028441"},"user_tz":-360},"id":"jXVWdmX9ftsx","outputId":"0ab63386-0219-4d9f-bf7a-6817f5f2e2c5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Failed to download (trying next):\n","HTTP Error 403: Forbidden\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ../../data/MNIST/raw/train-images-idx3-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 9912422/9912422 [00:00<00:00, 83698981.22it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting ../../data/MNIST/raw/train-images-idx3-ubyte.gz to ../../data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Failed to download (trying next):\n","HTTP Error 403: Forbidden\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ../../data/MNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 28881/28881 [00:00<00:00, 23539777.27it/s]"]},{"name":"stdout","output_type":"stream","text":["Extracting ../../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../../data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["Failed to download (trying next):\n","HTTP Error 403: Forbidden\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ../../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1648877/1648877 [00:00<00:00, 88472449.75it/s]"]},{"name":"stdout","output_type":"stream","text":["Extracting ../../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../../data/MNIST/raw\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n","Failed to download (trying next):\n","HTTP Error 403: Forbidden\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ../../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 4542/4542 [00:00<00:00, 6072849.46it/s]"]},{"name":"stdout","output_type":"stream","text":["Extracting ../../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../../data/MNIST/raw\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/5], Step [100/600], Loss: 0.1744\n","Epoch [1/5], Step [200/600], Loss: 0.0905\n","Epoch [1/5], Step [300/600], Loss: 0.0330\n","Epoch [1/5], Step [400/600], Loss: 0.0422\n","Epoch [1/5], Step [500/600], Loss: 0.1063\n","Epoch [1/5], Step [600/600], Loss: 0.0314\n","Epoch [2/5], Step [100/600], Loss: 0.0162\n","Epoch [2/5], Step [200/600], Loss: 0.0469\n","Epoch [2/5], Step [300/600], Loss: 0.0521\n","Epoch [2/5], Step [400/600], Loss: 0.0645\n","Epoch [2/5], Step [500/600], Loss: 0.0146\n","Epoch [2/5], Step [600/600], Loss: 0.0824\n","Epoch [3/5], Step [100/600], Loss: 0.0839\n","Epoch [3/5], Step [200/600], Loss: 0.0044\n","Epoch [3/5], Step [300/600], Loss: 0.0047\n","Epoch [3/5], Step [400/600], Loss: 0.0101\n","Epoch [3/5], Step [500/600], Loss: 0.0310\n","Epoch [3/5], Step [600/600], Loss: 0.0554\n","Epoch [4/5], Step [100/600], Loss: 0.0189\n","Epoch [4/5], Step [200/600], Loss: 0.1223\n","Epoch [4/5], Step [300/600], Loss: 0.0341\n","Epoch [4/5], Step [400/600], Loss: 0.0060\n","Epoch [4/5], Step [500/600], Loss: 0.0160\n","Epoch [4/5], Step [600/600], Loss: 0.0161\n","Epoch [5/5], Step [100/600], Loss: 0.0254\n","Epoch [5/5], Step [200/600], Loss: 0.0359\n","Epoch [5/5], Step [300/600], Loss: 0.0490\n","Epoch [5/5], Step [400/600], Loss: 0.0818\n","Epoch [5/5], Step [500/600], Loss: 0.0258\n","Epoch [5/5], Step [600/600], Loss: 0.0171\n","Test Accuracy of the model on the 10000 test images: 99.0 %\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torchvision\n","import torchvision.transforms as transforms\n","\n","\n","# Device configuration\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","\n","# Hyper parameters\n","num_epochs = 5\n","num_classes = 10\n","batch_size = 100\n","learning_rate = 0.001\n","\n","# MNIST dataset\n","train_dataset = torchvision.datasets.MNIST(root='../../data/',\n","                                           train=True,\n","                                           transform=transforms.ToTensor(),\n","                                           download=True)\n","\n","test_dataset = torchvision.datasets.MNIST(root='../../data/',\n","                                          train=False,\n","                                          transform=transforms.ToTensor())\n","\n","# Data loader\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n","                                           batch_size=batch_size,\n","                                           shuffle=True)\n","\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n","                                          batch_size=batch_size,\n","                                          shuffle=False)\n","\n","# Convolutional neural network (two convolutional layers)\n","class ConvNet(nn.Module):\n","    def __init__(self, num_classes=10):\n","        super(ConvNet, self).__init__()\n","        self.layer1 = nn.Sequential(\n","            nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2),\n","            nn.BatchNorm2d(16),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2))\n","        self.layer2 = nn.Sequential(\n","            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n","            nn.BatchNorm2d(32),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2))\n","        self.fc = nn.Linear(7*7*32, num_classes)\n","\n","    def forward(self, x):\n","        out = self.layer1(x)\n","        out = self.layer2(out)\n","        out = out.reshape(out.size(0), -1)\n","        out = self.fc(out)\n","        return out\n","\n","model = ConvNet(num_classes).to(device)\n","\n","# Loss and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","# Train the model\n","total_step = len(train_loader)\n","for epoch in range(num_epochs):\n","    for i, (images, labels) in enumerate(train_loader):\n","        images = images.to(device)\n","        labels = labels.to(device)\n","\n","        # Forward pass\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","\n","        # Backward and optimize\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        if (i+1) % 100 == 0:\n","            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n","                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n","\n","# Test the model\n","model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n","with torch.no_grad():\n","    correct = 0\n","    total = 0\n","    for images, labels in test_loader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        outputs = model(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","    print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))\n","\n","# Save the model checkpoint\n","torch.save(model.state_dict(), 'model.ckpt')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":318783,"status":"ok","timestamp":1721829618229,"user":{"displayName":"Abu Taher","userId":"13405938316250028441"},"user_tz":-360},"id":"GGWgu-1Zh32_","outputId":"70cf52bc-2840-4794-d0e6-a09e9b0017c9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../../data/cifar-10-python.tar.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 170498071/170498071 [00:01<00:00, 92475455.30it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting ../../data/cifar-10-python.tar.gz to ../../data/\n","Epoch [1/5], Step [100/500], Loss: 1.5215\n","Epoch [1/5], Step [200/500], Loss: 1.2867\n","Epoch [1/5], Step [300/500], Loss: 1.1437\n","Epoch [1/5], Step [400/500], Loss: 1.0519\n","Epoch [1/5], Step [500/500], Loss: 1.0643\n","Epoch [2/5], Step [100/500], Loss: 1.0213\n","Epoch [2/5], Step [200/500], Loss: 1.1774\n","Epoch [2/5], Step [300/500], Loss: 0.9975\n","Epoch [2/5], Step [400/500], Loss: 1.0800\n","Epoch [2/5], Step [500/500], Loss: 1.0477\n","Epoch [3/5], Step [100/500], Loss: 0.9161\n","Epoch [3/5], Step [200/500], Loss: 0.8516\n","Epoch [3/5], Step [300/500], Loss: 0.8496\n","Epoch [3/5], Step [400/500], Loss: 0.8878\n","Epoch [3/5], Step [500/500], Loss: 0.8231\n","Epoch [4/5], Step [100/500], Loss: 0.9097\n","Epoch [4/5], Step [200/500], Loss: 0.9218\n","Epoch [4/5], Step [300/500], Loss: 1.1430\n","Epoch [4/5], Step [400/500], Loss: 0.9144\n","Epoch [4/5], Step [500/500], Loss: 0.8095\n","Epoch [5/5], Step [100/500], Loss: 0.9182\n","Epoch [5/5], Step [200/500], Loss: 0.7350\n","Epoch [5/5], Step [300/500], Loss: 0.9040\n","Epoch [5/5], Step [400/500], Loss: 0.8923\n","Epoch [5/5], Step [500/500], Loss: 0.7408\n","Test Accuracy of the model on the 10000 test images: 64.79 %\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torchvision\n","import torchvision.transforms as transforms\n","\n","\n","# Device configuration\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","\n","# Hyper parameters\n","num_epochs = 5\n","num_classes = 10\n","batch_size = 100\n","learning_rate = 0.001\n","\n","# MNIST dataset\n","train_dataset = torchvision.datasets.CIFAR10(root='../../data/',\n","                                           train=True,\n","                                           transform=transforms.ToTensor(),\n","                                           download=True)\n","\n","test_dataset = torchvision.datasets.CIFAR10(root='../../data/',\n","                                          train=False,\n","                                          transform=transforms.ToTensor())\n","\n","# Data loader\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n","                                           batch_size=batch_size,\n","                                           shuffle=True)\n","\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n","                                          batch_size=batch_size,\n","                                          shuffle=False)\n","# Convolutional neural network (two convolutional layers)\n","class ConvNet(nn.Module):\n","    def __init__(self, num_classes=10):\n","        super(ConvNet, self).__init__()\n","        self.layer1 = nn.Sequential(\n","            nn.Conv2d(3, 16, kernel_size=5, stride=1, padding=2),\n","            nn.BatchNorm2d(16),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2))\n","        self.layer2 = nn.Sequential(\n","            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n","            nn.BatchNorm2d(32),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2))\n","        self.fc = nn.Linear(8*8*32, num_classes)\n","\n","    def forward(self, x):\n","        out = self.layer1(x)\n","        out = self.layer2(out)\n","        out = out.reshape(out.size(0), -1)\n","        out = self.fc(out)\n","        return out\n","\n","model = ConvNet(num_classes).to(device)\n","\n","# Loss and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","# Train the model\n","total_step = len(train_loader)\n","for epoch in range(num_epochs):\n","    for i, (images, labels) in enumerate(train_loader):\n","        images = images.to(device)\n","        labels = labels.to(device)\n","\n","        # Forward pass\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","\n","        # Backward and optimize\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        if (i+1) % 100 == 0:\n","            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n","                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n","\n","# Test the model\n","model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n","with torch.no_grad():\n","    correct = 0\n","    total = 0\n","    for images, labels in test_loader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        outputs = model(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","    print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))\n","\n","# Save the model checkpoint\n","torch.save(model.state_dict(), 'model.ckpt')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":482,"status":"ok","timestamp":1720978226895,"user":{"displayName":"Abu Taher","userId":"13405938316250028441"},"user_tz":-360},"id":"wx9nZuaIj-l6","outputId":"dee33c35-6353-45f9-a1df-4a10c15720ee"},"outputs":[{"data":{"text/plain":["torch.Size([3, 32, 32])"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["train_dataset[0][0].shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"K6cGVyW2nfDp","outputId":"d6f55298-193d-4600-f664-eb9ed6bade18"},"outputs":[{"name":"stdout","output_type":"stream","text":["Files already downloaded and verified\n","Epoch [1/50], Step [100/500], Loss: 1.7418\n","Epoch [1/50], Step [200/500], Loss: 1.7895\n","Epoch [1/50], Step [300/500], Loss: 1.4368\n","Epoch [1/50], Step [400/500], Loss: 1.6344\n","Epoch [1/50], Step [500/500], Loss: 1.4161\n","Epoch [2/50], Step [100/500], Loss: 1.3455\n","Epoch [2/50], Step [200/500], Loss: 1.4035\n","Epoch [2/50], Step [300/500], Loss: 1.3720\n","Epoch [2/50], Step [400/500], Loss: 1.4172\n","Epoch [2/50], Step [500/500], Loss: 1.5835\n","Epoch [3/50], Step [100/500], Loss: 1.5250\n","Epoch [3/50], Step [200/500], Loss: 1.3716\n","Epoch [3/50], Step [300/500], Loss: 1.4317\n","Epoch [3/50], Step [400/500], Loss: 1.3311\n","Epoch [3/50], Step [500/500], Loss: 1.3710\n","Epoch [4/50], Step [100/500], Loss: 1.1884\n","Epoch [4/50], Step [200/500], Loss: 1.3747\n","Epoch [4/50], Step [300/500], Loss: 1.2547\n","Epoch [4/50], Step [400/500], Loss: 1.2283\n","Epoch [4/50], Step [500/500], Loss: 1.3487\n","Epoch [5/50], Step [100/500], Loss: 1.0444\n","Epoch [5/50], Step [200/500], Loss: 1.0940\n","Epoch [5/50], Step [300/500], Loss: 1.1906\n","Epoch [5/50], Step [400/500], Loss: 1.3646\n","Epoch [5/50], Step [500/500], Loss: 1.3596\n","Epoch [6/50], Step [100/500], Loss: 1.2678\n","Epoch [6/50], Step [200/500], Loss: 1.4691\n","Epoch [6/50], Step [300/500], Loss: 1.3820\n","Epoch [6/50], Step [400/500], Loss: 1.2322\n","Epoch [6/50], Step [500/500], Loss: 1.1164\n","Epoch [7/50], Step [100/500], Loss: 1.1223\n","Epoch [7/50], Step [200/500], Loss: 1.3406\n","Epoch [7/50], Step [300/500], Loss: 1.1790\n","Epoch [7/50], Step [400/500], Loss: 1.3380\n","Epoch [7/50], Step [500/500], Loss: 1.0807\n","Epoch [8/50], Step [100/500], Loss: 1.1565\n","Epoch [8/50], Step [200/500], Loss: 1.0030\n","Epoch [8/50], Step [300/500], Loss: 1.3381\n","Epoch [8/50], Step [400/500], Loss: 1.3261\n","Epoch [8/50], Step [500/500], Loss: 1.1346\n","Epoch [9/50], Step [100/500], Loss: 1.0915\n","Epoch [9/50], Step [200/500], Loss: 1.1803\n","Epoch [9/50], Step [300/500], Loss: 1.1914\n","Epoch [9/50], Step [400/500], Loss: 1.3287\n","Epoch [9/50], Step [500/500], Loss: 1.2691\n","Epoch [10/50], Step [100/500], Loss: 1.0464\n","Epoch [10/50], Step [200/500], Loss: 0.9843\n","Epoch [10/50], Step [300/500], Loss: 1.2174\n","Epoch [10/50], Step [400/500], Loss: 1.1101\n","Epoch [10/50], Step [500/500], Loss: 1.1687\n","Epoch [11/50], Step [100/500], Loss: 1.1975\n","Epoch [11/50], Step [200/500], Loss: 1.1428\n","Epoch [11/50], Step [300/500], Loss: 1.2090\n","Epoch [11/50], Step [400/500], Loss: 1.2342\n","Epoch [11/50], Step [500/500], Loss: 1.1874\n","Epoch [12/50], Step [100/500], Loss: 1.2139\n","Epoch [12/50], Step [200/500], Loss: 1.0962\n","Epoch [12/50], Step [300/500], Loss: 1.3069\n","Epoch [12/50], Step [400/500], Loss: 1.0356\n","Epoch [12/50], Step [500/500], Loss: 1.4573\n","Epoch [13/50], Step [100/500], Loss: 1.0181\n","Epoch [13/50], Step [200/500], Loss: 1.0464\n","Epoch [13/50], Step [300/500], Loss: 1.2491\n","Epoch [13/50], Step [400/500], Loss: 1.0772\n","Epoch [13/50], Step [500/500], Loss: 1.1348\n","Epoch [14/50], Step [100/500], Loss: 1.0732\n","Epoch [14/50], Step [200/500], Loss: 1.2868\n","Epoch [14/50], Step [300/500], Loss: 1.2006\n","Epoch [14/50], Step [400/500], Loss: 0.9228\n","Epoch [14/50], Step [500/500], Loss: 1.0475\n","Epoch [15/50], Step [100/500], Loss: 1.0934\n","Epoch [15/50], Step [200/500], Loss: 1.2288\n","Epoch [15/50], Step [300/500], Loss: 1.2928\n","Epoch [15/50], Step [400/500], Loss: 1.1840\n","Epoch [15/50], Step [500/500], Loss: 1.0757\n","Epoch [16/50], Step [100/500], Loss: 1.0021\n","Epoch [16/50], Step [200/500], Loss: 1.1174\n","Epoch [16/50], Step [300/500], Loss: 1.2603\n","Epoch [16/50], Step [400/500], Loss: 1.2635\n","Epoch [16/50], Step [500/500], Loss: 1.2317\n","Epoch [17/50], Step [100/500], Loss: 1.3327\n","Epoch [17/50], Step [200/500], Loss: 0.9891\n","Epoch [17/50], Step [300/500], Loss: 1.1534\n","Epoch [17/50], Step [400/500], Loss: 1.1154\n","Epoch [17/50], Step [500/500], Loss: 0.9629\n","Epoch [18/50], Step [100/500], Loss: 0.9802\n","Epoch [18/50], Step [200/500], Loss: 1.2129\n","Epoch [18/50], Step [300/500], Loss: 0.9969\n","Epoch [18/50], Step [400/500], Loss: 1.2239\n","Epoch [18/50], Step [500/500], Loss: 1.2194\n","Epoch [19/50], Step [100/500], Loss: 1.2011\n","Epoch [19/50], Step [200/500], Loss: 1.0566\n","Epoch [19/50], Step [300/500], Loss: 1.2611\n","Epoch [19/50], Step [400/500], Loss: 1.1748\n","Epoch [19/50], Step [500/500], Loss: 1.1119\n","Epoch [20/50], Step [100/500], Loss: 1.0709\n","Epoch [20/50], Step [200/500], Loss: 1.2888\n","Epoch [20/50], Step [300/500], Loss: 1.1245\n","Epoch [20/50], Step [400/500], Loss: 1.1134\n","Epoch [20/50], Step [500/500], Loss: 0.9699\n","Epoch [21/50], Step [100/500], Loss: 1.0651\n","Epoch [21/50], Step [200/500], Loss: 1.2723\n","Epoch [21/50], Step [300/500], Loss: 1.1128\n","Epoch [21/50], Step [400/500], Loss: 1.1247\n","Epoch [21/50], Step [500/500], Loss: 1.1598\n","Epoch [22/50], Step [100/500], Loss: 1.0396\n","Epoch [22/50], Step [200/500], Loss: 0.9427\n","Epoch [22/50], Step [300/500], Loss: 1.1114\n","Epoch [22/50], Step [400/500], Loss: 1.0996\n","Epoch [22/50], Step [500/500], Loss: 1.1296\n","Epoch [23/50], Step [100/500], Loss: 0.9651\n","Epoch [23/50], Step [200/500], Loss: 1.2020\n","Epoch [23/50], Step [300/500], Loss: 1.0405\n","Epoch [23/50], Step [400/500], Loss: 1.2745\n","Epoch [23/50], Step [500/500], Loss: 0.8725\n","Epoch [24/50], Step [100/500], Loss: 1.0148\n","Epoch [24/50], Step [200/500], Loss: 0.9016\n","Epoch [24/50], Step [300/500], Loss: 0.9630\n","Epoch [24/50], Step [400/500], Loss: 1.0124\n","Epoch [24/50], Step [500/500], Loss: 1.2167\n","Epoch [25/50], Step [100/500], Loss: 1.0238\n","Epoch [25/50], Step [200/500], Loss: 1.1575\n","Epoch [25/50], Step [300/500], Loss: 1.1026\n","Epoch [25/50], Step [400/500], Loss: 0.8764\n","Epoch [25/50], Step [500/500], Loss: 0.9877\n","Epoch [26/50], Step [100/500], Loss: 1.0971\n","Epoch [26/50], Step [200/500], Loss: 0.9980\n","Epoch [26/50], Step [300/500], Loss: 1.1403\n","Epoch [26/50], Step [400/500], Loss: 1.0166\n","Epoch [26/50], Step [500/500], Loss: 1.2124\n","Epoch [27/50], Step [100/500], Loss: 1.1043\n","Epoch [27/50], Step [200/500], Loss: 0.8159\n","Epoch [27/50], Step [300/500], Loss: 1.0557\n","Epoch [27/50], Step [400/500], Loss: 0.9236\n","Epoch [27/50], Step [500/500], Loss: 1.1305\n","Epoch [28/50], Step [100/500], Loss: 0.9362\n","Epoch [28/50], Step [200/500], Loss: 1.2481\n","Epoch [28/50], Step [300/500], Loss: 0.8600\n","Epoch [28/50], Step [400/500], Loss: 1.0750\n","Epoch [28/50], Step [500/500], Loss: 0.9425\n","Epoch [29/50], Step [100/500], Loss: 0.9795\n","Epoch [29/50], Step [200/500], Loss: 0.9341\n","Epoch [29/50], Step [300/500], Loss: 0.9914\n","Epoch [29/50], Step [400/500], Loss: 1.0556\n","Epoch [29/50], Step [500/500], Loss: 1.1075\n","Epoch [30/50], Step [100/500], Loss: 1.2627\n","Epoch [30/50], Step [200/500], Loss: 1.1955\n","Epoch [30/50], Step [300/500], Loss: 1.0853\n","Epoch [30/50], Step [400/500], Loss: 0.8192\n","Epoch [30/50], Step [500/500], Loss: 1.2833\n","Epoch [31/50], Step [100/500], Loss: 0.9371\n","Epoch [31/50], Step [200/500], Loss: 0.7777\n","Epoch [31/50], Step [300/500], Loss: 1.0355\n","Epoch [31/50], Step [400/500], Loss: 1.2908\n","Epoch [31/50], Step [500/500], Loss: 1.1552\n","Epoch [32/50], Step [100/500], Loss: 1.1880\n","Epoch [32/50], Step [200/500], Loss: 1.1549\n","Epoch [32/50], Step [300/500], Loss: 1.1146\n","Epoch [32/50], Step [400/500], Loss: 1.1736\n","Epoch [32/50], Step [500/500], Loss: 1.2028\n","Epoch [33/50], Step [100/500], Loss: 1.1823\n","Epoch [33/50], Step [200/500], Loss: 1.0503\n","Epoch [33/50], Step [300/500], Loss: 1.0654\n","Epoch [33/50], Step [400/500], Loss: 1.1478\n","Epoch [33/50], Step [500/500], Loss: 1.0488\n","Epoch [34/50], Step [100/500], Loss: 0.8904\n","Epoch [34/50], Step [200/500], Loss: 1.1113\n","Epoch [34/50], Step [300/500], Loss: 0.8666\n","Epoch [34/50], Step [400/500], Loss: 0.9800\n","Epoch [34/50], Step [500/500], Loss: 0.9519\n","Epoch [35/50], Step [100/500], Loss: 0.9124\n","Epoch [35/50], Step [200/500], Loss: 1.0743\n","Epoch [35/50], Step [300/500], Loss: 1.0425\n","Epoch [35/50], Step [400/500], Loss: 1.0938\n","Epoch [35/50], Step [500/500], Loss: 1.2999\n","Epoch [36/50], Step [100/500], Loss: 0.9903\n","Epoch [36/50], Step [200/500], Loss: 1.1022\n","Epoch [36/50], Step [300/500], Loss: 0.9270\n","Epoch [36/50], Step [400/500], Loss: 0.9067\n","Epoch [36/50], Step [500/500], Loss: 1.1353\n","Epoch [37/50], Step [100/500], Loss: 0.8521\n","Epoch [37/50], Step [200/500], Loss: 0.9871\n","Epoch [37/50], Step [300/500], Loss: 1.0566\n","Epoch [37/50], Step [400/500], Loss: 1.0381\n","Epoch [37/50], Step [500/500], Loss: 0.9037\n","Epoch [38/50], Step [100/500], Loss: 1.0418\n","Epoch [38/50], Step [200/500], Loss: 0.9432\n","Epoch [38/50], Step [300/500], Loss: 0.9628\n","Epoch [38/50], Step [400/500], Loss: 1.0613\n","Epoch [38/50], Step [500/500], Loss: 1.0592\n","Epoch [39/50], Step [100/500], Loss: 0.9188\n","Epoch [39/50], Step [200/500], Loss: 1.1960\n","Epoch [39/50], Step [300/500], Loss: 0.7876\n","Epoch [39/50], Step [400/500], Loss: 0.9838\n","Epoch [39/50], Step [500/500], Loss: 1.0084\n","Epoch [40/50], Step [100/500], Loss: 0.8133\n","Epoch [40/50], Step [200/500], Loss: 1.1413\n","Epoch [40/50], Step [300/500], Loss: 1.2685\n","Epoch [40/50], Step [400/500], Loss: 0.8975\n","Epoch [40/50], Step [500/500], Loss: 1.0396\n","Epoch [41/50], Step [100/500], Loss: 0.9046\n","Epoch [41/50], Step [200/500], Loss: 0.9557\n","Epoch [41/50], Step [300/500], Loss: 1.0765\n","Epoch [41/50], Step [400/500], Loss: 0.9370\n","Epoch [41/50], Step [500/500], Loss: 1.0974\n","Epoch [42/50], Step [100/500], Loss: 1.1991\n","Epoch [42/50], Step [200/500], Loss: 0.9305\n","Epoch [42/50], Step [300/500], Loss: 1.0356\n","Epoch [42/50], Step [400/500], Loss: 0.8771\n","Epoch [42/50], Step [500/500], Loss: 0.8887\n","Epoch [43/50], Step [100/500], Loss: 0.8448\n","Epoch [43/50], Step [200/500], Loss: 0.8375\n","Epoch [43/50], Step [300/500], Loss: 1.0463\n","Epoch [43/50], Step [400/500], Loss: 1.1456\n","Epoch [43/50], Step [500/500], Loss: 0.9432\n","Epoch [44/50], Step [100/500], Loss: 0.9866\n","Epoch [44/50], Step [200/500], Loss: 1.0838\n","Epoch [44/50], Step [300/500], Loss: 1.0812\n","Epoch [44/50], Step [400/500], Loss: 0.9999\n","Epoch [44/50], Step [500/500], Loss: 1.1939\n","Epoch [45/50], Step [100/500], Loss: 0.9320\n","Epoch [45/50], Step [200/500], Loss: 0.8982\n","Epoch [45/50], Step [300/500], Loss: 0.9435\n","Epoch [45/50], Step [400/500], Loss: 0.9514\n","Epoch [45/50], Step [500/500], Loss: 1.1433\n","Epoch [46/50], Step [100/500], Loss: 0.9996\n","Epoch [46/50], Step [200/500], Loss: 1.1929\n","Epoch [46/50], Step [300/500], Loss: 0.9473\n","Epoch [46/50], Step [400/500], Loss: 1.0822\n","Epoch [46/50], Step [500/500], Loss: 1.1271\n","Epoch [47/50], Step [100/500], Loss: 0.9465\n","Epoch [47/50], Step [200/500], Loss: 0.8219\n","Epoch [47/50], Step [300/500], Loss: 0.9780\n","Epoch [47/50], Step [400/500], Loss: 1.0857\n","Epoch [47/50], Step [500/500], Loss: 0.9147\n","Epoch [48/50], Step [100/500], Loss: 0.9676\n","Epoch [48/50], Step [200/500], Loss: 0.7629\n","Epoch [48/50], Step [300/500], Loss: 0.9876\n","Epoch [48/50], Step [400/500], Loss: 0.9377\n","Epoch [48/50], Step [500/500], Loss: 1.1684\n","Epoch [49/50], Step [100/500], Loss: 0.7897\n","Epoch [49/50], Step [200/500], Loss: 0.9219\n","Epoch [49/50], Step [300/500], Loss: 1.2588\n","Epoch [49/50], Step [400/500], Loss: 1.1687\n","Epoch [49/50], Step [500/500], Loss: 0.9459\n","Epoch [50/50], Step [100/500], Loss: 1.1091\n","Epoch [50/50], Step [200/500], Loss: 0.9494\n","Epoch [50/50], Step [300/500], Loss: 1.1262\n","Epoch [50/50], Step [400/500], Loss: 1.0289\n","Epoch [50/50], Step [500/500], Loss: 1.0046\n","Test Accuracy of the model on the 10000 test images: 55.27 %\n"]}],"source":["\n","import torch\n","import torch.nn as nn\n","import torchvision\n","import torchvision.transforms as transforms\n","\n","\n","# Device configuration\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","\n","# Hyper parameters\n","num_epochs = 50\n","num_classes = 10\n","batch_size = 100\n","learning_rate = 0.001\n","\n","# MNIST dataset\n","train_dataset = torchvision.datasets.CIFAR10(root='../../data/',\n","                                           train=True,\n","                                           transform=transforms.ToTensor(),\n","                                           download=True)\n","\n","test_dataset = torchvision.datasets.CIFAR10(root='../../data/',\n","                                          train=False,\n","                                          transform=transforms.ToTensor())\n","\n","# Data loader\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n","                                           batch_size=batch_size,\n","                                           shuffle=True)\n","\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n","                                          batch_size=batch_size,\n","                                          shuffle=False)\n","\n","\n","# Convolutional neural network (two convolutional layers)\n","class ConvNet(nn.Module):\n","    def __init__(self, num_classes=10):\n","        super(ConvNet, self).__init__()\n","        self.layer1 = nn.Sequential(\n","            nn.Conv2d(3, 16, kernel_size=1, stride=1, padding=2),\n","            nn.BatchNorm2d(16),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2))\n","        self.layer2 = nn.Sequential(\n","            nn.Conv2d(16, 32, kernel_size=1, stride=1, padding=2),\n","            nn.BatchNorm2d(32),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2))\n","        self.fc = nn.Linear(11*11*32, num_classes)\n","\n","    def forward(self, x):\n","        out = self.layer1(x)\n","        out = self.layer2(out)\n","        out = out.reshape(out.size(0), -1)\n","        out = self.fc(out)\n","        return out\n","\n","model = ConvNet(num_classes).to(device)\n","\n","# Loss and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","# Train the model\n","total_step = len(train_loader)\n","for epoch in range(num_epochs):\n","    for i, (images, labels) in enumerate(train_loader):\n","        images = images.to(device)\n","        labels = labels.to(device)\n","\n","        # Forward pass\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","\n","        # Backward and optimize\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        if (i+1) % 100 == 0:\n","            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n","                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n","\n","# Test the model\n","model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n","with torch.no_grad():\n","    correct = 0\n","    total = 0\n","    for images, labels in test_loader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        outputs = model(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","    print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))\n","\n","# Save the model checkpoint\n","torch.save(model.state_dict(), 'model.ckpt')"]}],"metadata":{"colab":{"provenance":[{"file_id":"1zKYkCeNOGyDaran5KJLnRl34hhLsvFdQ","timestamp":1723635742744}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}