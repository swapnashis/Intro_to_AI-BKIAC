{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNPaln4pBJ882VaU6tFRUjl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"g4K4AA6d_ii5","executionInfo":{"status":"ok","timestamp":1720352932325,"user_tz":-360,"elapsed":12242,"user":{"displayName":"Swapnashis Bhattacharjee","userId":"07614146342855752455"}}},"outputs":[],"source":["import torch\n","import torchvision\n","import torch.nn as nn\n","import numpy as np\n","import torchvision.transforms as transforms"]},{"cell_type":"code","source":["# ================================================================== #\n","#                         Table of Contents                          #\n","# ================================================================== #\n","\n","# 1. Basic autograd example 1               (Line 25 to 39)\n","# 2. Basic autograd example 2               (Line 46 to 83)\n","# 3. Loading data from numpy                (Line 90 to 97)\n","# 4. Input pipline                          (Line 104 to 129)\n","# 5. Input pipline for custom dataset       (Line 136 to 156)\n","# 6. Pretrained model                       (Line 163 to 176)\n","# 7. Save and load model                    (Line 183 to 189)"],"metadata":{"id":"-e5qnRcOBkFE","executionInfo":{"status":"ok","timestamp":1720352994568,"user_tz":-360,"elapsed":964,"user":{"displayName":"Swapnashis Bhattacharjee","userId":"07614146342855752455"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# ================================================================== #\n","#                     1. Basic autograd example 1                    #\n","# ================================================================== #\n","\n","# Create tensors.\n","# x = torch.tensor(1., requires_grad=True)\n","# w = torch.tensor(2., requires_grad=True)\n","# b = torch.tensor(3., requires_grad=True)\n","\n","x = torch.tensor(9., requires_grad=True)\n","w = torch.tensor(6., requires_grad=True)\n","b = torch.tensor(3., requires_grad=True)\n","\n","# Build a computational graph.\n","y = w * x + b    # y = 2 * x + 3\n","\n","# Compute gradients.\n","y.backward()\n","\n","# Print out the gradients.\n","print(x.grad)    # x.grad = 2\n","print(w.grad)    # w.grad = 1\n","print(b.grad)    # b.grad = 1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wEvSBH5nB2oP","executionInfo":{"status":"ok","timestamp":1720354436885,"user_tz":-360,"elapsed":524,"user":{"displayName":"Swapnashis Bhattacharjee","userId":"07614146342855752455"}},"outputId":"603eb07c-d07a-445d-ec2d-0b314994723c"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(6.)\n","tensor(9.)\n","tensor(1.)\n"]}]},{"cell_type":"code","source":["# ================================================================== #\n","#                    2. Basic autograd example 2                     #\n","# ================================================================== #\n","\n","# Create tensors of shape (10, 3) and (10, 2).\n","x = torch.randn(10, 3)\n","y = torch.randn(10, 2)\n","\n","# Build a fully connected layer.\n","linear = nn.Linear(3, 2)\n","print ('w: ', linear.weight)\n","print ('b: ', linear.bias)\n","\n","# Build loss function and optimizer.\n","criterion = nn.MSELoss()\n","optimizer = torch.optim.SGD(linear.parameters(), lr=0.01)\n","\n","# Forward pass.\n","pred = linear(x)\n","\n","# Compute loss.\n","loss = criterion(pred, y)\n","print('loss: ', loss.item())\n","\n","# Backward pass.\n","loss.backward()\n","\n","# Print out the gradients.\n","print ('dL/dw: ', linear.weight.grad)\n","print ('dL/db: ', linear.bias.grad)\n","\n","# 1-step gradient descent.\n","optimizer.step()\n","\n","# You can also perform gradient descent at the low level.\n","# linear.weight.data.sub_(0.01 * linear.weight.grad.data)\n","# linear.bias.data.sub_(0.01 * linear.bias.grad.data)\n","\n","# Print out the loss after 1-step gradient descent.\n","pred = linear(x)\n","loss = criterion(pred, y)\n","print('loss after 1 step optimization: ', loss.item())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kBuryikhDRgP","executionInfo":{"status":"ok","timestamp":1720354775651,"user_tz":-360,"elapsed":6,"user":{"displayName":"Swapnashis Bhattacharjee","userId":"07614146342855752455"}},"outputId":"300976fc-e844-49d1-d120-aa281b08addf"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["w:  Parameter containing:\n","tensor([[-0.5461,  0.4001, -0.1987],\n","        [-0.4699, -0.1347, -0.2011]], requires_grad=True)\n","b:  Parameter containing:\n","tensor([0.4581, 0.0070], requires_grad=True)\n","loss:  1.2233388423919678\n","dL/dw:  tensor([[-0.6762,  0.0332, -0.0907],\n","        [-0.7105,  0.3290, -0.2043]])\n","dL/db:  tensor([-0.1887, -0.1697])\n","loss after 1 step optimization:  1.1107934713363647\n"]}]},{"cell_type":"code","source":["# Create tensors of shape (10, 3) and (10, 2).\n","x = torch.randn(10, 3)\n","y = torch.randn(10, 2)"],"metadata":{"id":"TrSs2f5TFljO","executionInfo":{"status":"ok","timestamp":1720354445419,"user_tz":-360,"elapsed":529,"user":{"displayName":"Swapnashis Bhattacharjee","userId":"07614146342855752455"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["# Build a fully connected layer.\n","linear = nn.Linear(3, 2)\n","print ('w: ', linear.weight)\n","print ('b: ', linear.bias)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kaC7E9o2Frjj","executionInfo":{"status":"ok","timestamp":1720354447494,"user_tz":-360,"elapsed":5,"user":{"displayName":"Swapnashis Bhattacharjee","userId":"07614146342855752455"}},"outputId":"b44a39ba-6f0d-4fbe-dff9-a04eabe7bd21"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["w:  Parameter containing:\n","tensor([[-0.4832,  0.4972, -0.4299],\n","        [-0.0636,  0.2886,  0.4912]], requires_grad=True)\n","b:  Parameter containing:\n","tensor([-0.2148, -0.4603], requires_grad=True)\n"]}]},{"cell_type":"code","source":["# Build loss function and optimizer.\n","criterion = nn.MSELoss()\n","optimizer = torch.optim.SGD(linear.parameters(), lr=0.01)"],"metadata":{"id":"_6VFrs4yF2fj","executionInfo":{"status":"ok","timestamp":1720354450648,"user_tz":-360,"elapsed":524,"user":{"displayName":"Swapnashis Bhattacharjee","userId":"07614146342855752455"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["# Forward pass.\n","pred = linear(x)"],"metadata":{"id":"SjNZmRSVF3T9","executionInfo":{"status":"ok","timestamp":1720354155007,"user_tz":-360,"elapsed":6,"user":{"displayName":"Swapnashis Bhattacharjee","userId":"07614146342855752455"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# Compute loss.\n","loss = criterion(pred, y)\n","print('loss: ', loss.item())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JaGHphs9F7K1","executionInfo":{"status":"ok","timestamp":1720354157125,"user_tz":-360,"elapsed":6,"user":{"displayName":"Swapnashis Bhattacharjee","userId":"07614146342855752455"}},"outputId":"d76c725d-ad2a-4b80-c7eb-933cb516835f"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["loss:  2.0848326683044434\n"]}]},{"cell_type":"code","source":["# Backward pass.\n","loss.backward()"],"metadata":{"id":"2R2NfpYTGRJO","executionInfo":{"status":"ok","timestamp":1720354169284,"user_tz":-360,"elapsed":531,"user":{"displayName":"Swapnashis Bhattacharjee","userId":"07614146342855752455"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["# Print out the gradients.\n","print ('dL/dw: ', linear.weight.grad)\n","print ('dL/db: ', linear.bias.grad)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UKD4DTUgGVzd","executionInfo":{"status":"ok","timestamp":1720354206240,"user_tz":-360,"elapsed":489,"user":{"displayName":"Swapnashis Bhattacharjee","userId":"07614146342855752455"}},"outputId":"87599925-7faf-4137-973c-79d2bbbf4578"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["dL/dw:  tensor([[-1.0422, -0.5952,  1.1670],\n","        [ 0.0703,  1.0051,  0.0018]])\n","dL/db:  tensor([-0.1642,  0.8126])\n"]}]},{"cell_type":"code","source":["# 1-step gradient descent.\n","optimizer.step()"],"metadata":{"id":"p4VMQCRKGe1F","executionInfo":{"status":"ok","timestamp":1720354217481,"user_tz":-360,"elapsed":499,"user":{"displayName":"Swapnashis Bhattacharjee","userId":"07614146342855752455"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["# You can also perform gradient descent at the low level.\n","# linear.weight.data.sub_(0.01 * linear.weight.grad.data)\n","# linear.bias.data.sub_(0.01 * linear.bias.grad.data)\n","\n","# Print out the loss after 1-step gradient descent.\n","pred = linear(x)\n","loss = criterion(pred, y)\n","print('loss after 1 step optimization: ', loss.item())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r27FlFTyGhkV","executionInfo":{"status":"ok","timestamp":1720354252759,"user_tz":-360,"elapsed":649,"user":{"displayName":"Swapnashis Bhattacharjee","userId":"07614146342855752455"}},"outputId":"3cd828f7-0e17-4bb2-bc0e-219da39ac760"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["loss after 1 step optimization:  2.040153741836548\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"o3rAOG9rGqJu"},"execution_count":null,"outputs":[]}]}